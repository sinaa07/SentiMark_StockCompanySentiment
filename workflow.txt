
///////////////////////////////////////////////////////////////////////////////////////

Complete Pipeline Flow Summary:

User Input → UserInputProcessor → Validates and formats company selection
News Collection → NewsCollector → Orchestrates RSS fetching and caching
RSS Fetching → RSSManager → Parallel fetch from multiple financial news sources
Content Filtering → ContentFilter → Relevance scoring and deduplication
FinBERT Prep → FinBERTPreprocessor → Chunking and API batch formatting
Sentiment Analysis → FinBERTClient → API calls and result aggregation
Final Output → Sentiment scores ready for dashboard/visualization

///////////////////////////////////////////////////////////////////////////////////////

User Input Processor (user_input_processor.py)
Input Handling Functions:
process_raw_input() - Clean and sanitize user text, normalize case and spacing
validate_input_length() - Check if input meets minimum character requirements
apply_debouncing() - Wait for user to stop typing before processing queries

Autocomplete Functions:
get_autocomplete_suggestions() - Main autocomplete entry point with validation and database search
format_suggestions_for_ui() - Convert database results to UI dropdown format
_highlight_search_term() - Add highlighting markers to matched text in suggestions
handle_no_results() - Provide helpful suggestions when no matches found

Selection Processing Functions:
handle_user_selection() - Main function to process selected company, validate and prepare data
prepare_for_news_scraper() - Format company data for news pipeline integration
_generate_search_terms() - Create optimized search keywords from company data

Utility Functions:
cache_recent_searches() - Store user's recent selections for quick access
get_recent_searches() - Retrieve cached recent searches
handle_errors() - Centralized error handling with consistent response format
test_connection() - Test processor and database connectivity
get_stats() - Return processor statistics and usage metrics

///////////////////////////////////////////////////////////////////////////////////////

RSS Manager (rss_manager.py)
Core Functions:

fetch_all_rss_feeds() - Parallel fetch from all configured RSS sources, returns combined articles
_fetch_single_rss_feed() - Fetch from one RSS source with retry logic and backup URLs
parse_rss_content() - Parse RSS XML using feedparser, extract article data
_extract_article_data() - Convert RSS entry to standardized article dictionary
_compile_fetch_results() - Combine results from multiple sources into final output
handle_rss_failures() - Analyze failed sources and provide recommendations
test_single_source() - Debug individual RSS source connectivity
get_source_status() - Return configuration status of all RSS sources

Utility Functions:

_safe_get_text() - Safely extract text from RSS fields with fallbacks
_extract_publish_date() - Parse and standardize publication dates
_extract_categories() - Extract tags/categories from RSS entries
_create_empty_result() - Create error response structure

///////////////////////////////////////////////////////////////////////////////////////

Content Filter (content_filter.py)
Main Functions:

filter_company_articles() - Main entry point, applies complete filtering pipeline
check_article_relevance() - Calculate relevance score (0-1) using company name/ticker matching
deduplicate_articles() - Remove duplicate articles using title similarity and URL matching
sort_by_recency() - Sort by relevance score then publication date (newest first)

Relevance Scoring Functions:
_calculate_company_name_score() - Score based on company name presence in text
_calculate_keyword_score() - Score based on financial keywords (earnings, profit, etc.)
_calculate_context_score() - Higher weight for matches in title vs description
_extract_company_identifiers() - Extract all possible company identifiers for matching

Deduplication Functions:
_generate_article_hash() - Create content hash for duplicate detection
_calculate_title_similarity() - Calculate Jaccard similarity between titles
_normalize_title() - Clean and normalize titles for comparison

Utility Functions:
_filter_by_date() - Filter out articles older than max_days_old
_parse_article_date() - Parse various date formats to datetime objects
_clean_text() - Remove HTML tags, normalize unicode, clean whitespace
_clean_company_name() - Remove common suffixes (Ltd, Limited, etc.)

///////////////////////////////////////////////////////////////////////////////////////

News Collector (news_collector.py)
Main Functions:

collect_company_news() - Main orchestrator, handles cache-first news collection
check_cache_first() - Check SQLite cache for valid articles before fetching
fetch_fresh_news() - Fetch new articles when cache miss occurs
store_news_cache() - Cache articles with expiration dates

Database Functions:

_ensure_news_tables() - Create news cache database tables and indexes
cleanup_expired_cache() - Remove expired cache entries
get_cache_stats() - Return cache statistics and metrics

Processing Functions:

_prepare_finbert_input() - Basic preparation for FinBERT (will use preprocessor)
_format_final_output() - Format response with metadata and processing stats
_fetch_rss_articles_mvp() - MVP RSS fetching (placeholder using mock data)
_filter_articles_mvp() - Basic keyword filtering (will use ContentFilter)

///////////////////////////////////////////////////////////////////////////////////////

FinBERT Preprocessor (finbert_preprocessor.py)
Main Functions:

prepare_for_finbert() - Main entry point, converts filtered articles to FinBERT batches
chunk_long_articles() - Split articles exceeding token limits while preserving context
create_finbert_input_batch() - Group chunks into API-optimized batches

Processing Functions:

_clean_articles() - Clean text and combine title+content for processing
_create_context_aware_chunks() - Create overlapping chunks preserving sentence boundaries
_split_into_sentences() - Split text into sentences handling financial abbreviations
_get_overlap_text() - Extract overlap text from chunk endings for continuity

///////////////////////////////////////////////////////////////////////////////////////

FinBERT Client (finbert_client.py) (Based on typical implementation)
Main API Functions:

analyze_sentiment_batch() - Send batched articles to FinBERT API for sentiment analysis
analyze_single_text() - Process individual text for sentiment scoring
process_preprocessed_batches() - Handle output from FinBERTPreprocessor

Request Management Functions:

_make_api_request() - Handle HTTP requests to FinBERT endpoint with retries
_handle_rate_limiting() - Manage API rate limits and backoff strategies
_validate_api_response() - Check API response format and extract results

Result Processing Functions:

_parse_sentiment_scores() - Extract confidence scores for positive/negative/neutral
_aggregate_chunk_sentiments() - Combine multiple chunk results into article-level sentiment
_format_analysis_results() - Structure output for pipeline consumption

Configuration Functions:

_load_api_config() - Load API endpoints, keys, and request parameters
_setup_request_session() - Configure HTTP session with headers and timeouts
get_client_stats() - Return API usage statistics and performance metrics

///////////////////////////////////////////////////////////////////////////////////////

